{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s:%(levelname)s:%(message)s\", datefmt=\"%d-%M-%Y %H:%M:%S\", level=logging.DEBUG)\n",
    "def merge_tax(file_list, name_list, format='json'):\n",
    "    total_json = {}\n",
    "    total_df = pd.DataFrame()\n",
    "    logging.info('merge_tax...')\n",
    "    for f, sample_name in zip(file_list, name_list):\n",
    "        with open(f, 'rt') as h:\n",
    "            res_json = json.load(h)\n",
    "            total_json[sample_name] = res_json['tax_value_dict']\n",
    "            res_df = pd.DataFrame.from_dict(res_json['tax_value_dict']).reset_index().set_index(['tax_level','index']).rename(columns={'relative_abundance':sample_name})\n",
    "        total_df = pd.concat([total_df, res_df], axis=1)\n",
    "    if format == 'json':\n",
    "        return total_json\n",
    "    return total_df\n",
    "\n",
    "def merge_json(file_list, name_list, key='alpha_dict', format='json'):\n",
    "    total_json = {}\n",
    "    total_df = pd.DataFrame()\n",
    "    logging.info(f'merge_{key}...')\n",
    "    for f, sample_name in zip(file_list, name_list):\n",
    "        with open(f, 'rt') as h:\n",
    "            res_json = json.load(h)\n",
    "            total_json[sample_name] = res_json[key]\n",
    "            res_df = pd.DataFrame.from_dict(res_json[key], orient='index').rename(columns={0:sample_name})\n",
    "        total_df = pd.concat([total_df, res_df], axis=1)\n",
    "    if format == 'json':\n",
    "        return total_json\n",
    "    return total_df\n",
    "\n",
    "def get_file_list(res_dir):\n",
    "    len(os.listdir(os.path.join(res_dir, os.listdir(res_dir)[0])))\n",
    "    n = 0\n",
    "    res_file_list = []\n",
    "    sample_name_list = []\n",
    "    for fir_d in os.listdir(res_dir):\n",
    "        sec_d = os.path.join(res_dir, fir_d)\n",
    "        for sample in os.listdir(sec_d):\n",
    "            res_file = os.path.join(sec_d, sample, f\"{sample}.res.json\")\n",
    "            if os.path.isfile(res_file):\n",
    "                n+=1\n",
    "                res_file_list.append(res_file)\n",
    "                sample_name_list.append(sample)\n",
    "            else:\n",
    "                logging.info(res_file)\n",
    "    logging.info(f\"total sample: {n}\")\n",
    "    return res_file_list, sample_name_list\n",
    "\n",
    "def merge_res(file_list, sample_list, outdir):\n",
    "    # total_json = {}\n",
    "    df = merge_tax(file_list, sample_list, format='df')\n",
    "    df = df.reset_index()\n",
    "    tax_level = df['tax_level'].unique()\n",
    "    for t in tax_level:\n",
    "        df[df['tax_level'] == t].fillna(0).drop('tax_level',axis=1).to_csv(os.path.join(outdir, f'tax_{t}.csv'), sep='\\t', index=False)\n",
    "\n",
    "    for k in ['alpha_dict', 'rgi_res_dict', 'vf_res_dict', 'pathway_res_dict']:\n",
    "        df = merge_json(file_list, sample_list, key=k, format='df')\n",
    "        df.fillna(0).to_csv(os.path.join(outdir, f'{k.split(\"_\")[0]}.csv'), sep='\\t')\n",
    "\n",
    "    # with open(outfile, 'wb') as f:\n",
    "        # pickle.dump(total_json, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter, usage=f'python {__file__} -d /home/hdd/gmxMeta/db/M2023/ -o /home/hdd/gmxMeta/db/Merge/' )\n",
    "    parser.add_argument('-d','--res_dir',required='True',help='result dir path')\n",
    "    parser.add_argument('-o','--out_dir',required='True',help='merge result dir')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # out_file = os.path.join(args.out_dir, 'test.out.df.pickle')\n",
    "    file_list, sample_list = get_file_list(args.res_dir)\n",
    "    merge_res(file_list, sample_list, args.out_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/mnt/c/work/metagenome/gmxMeta_276/gmxMeta_data/'\n",
    "len(os.listdir(os.path.join(res_dir, os.listdir(res_dir)[0])))\n",
    "n = 0\n",
    "res_file_list = []\n",
    "sample_name_list = []\n",
    "for fir_d in os.listdir(res_dir):\n",
    "    sec_d = os.path.join(res_dir, fir_d)\n",
    "    for sample in os.listdir(sec_d):\n",
    "        res_file = os.path.join(sec_d, sample, f\"{sample}.res.json\")\n",
    "        if os.path.isfile(res_file):\n",
    "            n+=1\n",
    "            res_file_list.append(res_file)\n",
    "            sample_name_list.append(sample)\n",
    "        else:\n",
    "            print(res_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
